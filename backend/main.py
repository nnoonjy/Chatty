import os
import shutil
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv  # .env íŒŒì¼ ë¡œë“œìš©

# LangChain ê´€ë ¨
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import WebBaseLoader, PyPDFLoader, DirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# 1. í™˜ê²½ ì„¤ì • (.env íŒŒì¼ì—ì„œ í‚¤ ê°€ì ¸ì˜¤ê¸°)
load_dotenv()

# API í‚¤ í™•ì¸ (ë””ë²„ê¹…ìš©)
if not os.getenv("OPENAI_API_KEY"):
    print("âš ï¸ ì˜¤ë¥˜: .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- ì„¤ì • ---
TARGET_URLS = [
    "https://onestop.pusan.ac.kr/page?menuCD=000000000000002",
    "https://onestop.pusan.ac.kr/page?menuCD=000000000000003",
    "https://onestop.pusan.ac.kr/page?menuCD=000000000000421",
    "https://onestop.pusan.ac.kr/page?menuCD=000000000000004",
    "https://onestop.pusan.ac.kr/page?menuCD=000000000000005",
    "https://onestop.pusan.ac.kr/page?menuCD=000000000000006",
    "https://onestop.pusan.ac.kr/page?menuCD=000000000000007",
    "https://onestop.pusan.ac.kr/page?menuCD=000000000000008",
    "https://onestop.pusan.ac.kr/page?menuCD=000000000000009"
]
DATA_PATH = "./data"
CHROMA_PATH = "./chroma_db"


def load_and_process_data():
    documents = []
    print("ğŸŒ ì›¹ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    try:
        web_loader = WebBaseLoader(TARGET_URLS)
        documents.extend(web_loader.load())
    except Exception as e:
        print(f"âš ï¸ ì›¹ í¬ë¡¤ë§ ìŠ¤í‚µ: {e}")

    if os.path.exists(DATA_PATH):
        print("ğŸ“‚ ë¡œì»¬ íŒŒì¼(PDF/TXT) ìˆ˜ì§‘ ì¤‘...")
        # PDF
        pdf_loader = DirectoryLoader(DATA_PATH, glob="**/*.pdf", loader_cls=PyPDFLoader)
        documents.extend(pdf_loader.load())
        # TXT
        txt_loader = DirectoryLoader(DATA_PATH, glob="**/*.txt")  # TextLoader ìë™ ì ìš©ë¨
        documents.extend(txt_loader.load())

    if not documents:
        return None

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(documents)

    # DB ì´ˆê¸°í™” ë° ì¬ìƒì„±
    if os.path.exists(CHROMA_PATH):
        shutil.rmtree(CHROMA_PATH)

    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=OpenAIEmbeddings(),
        persist_directory=CHROMA_PATH
    )
    print("âœ… ì„ë² ë”© ì™„ë£Œ ë° DB ì €ì¥ë¨!")
    return vectorstore


# ì„œë²„ ì‹œì‘ ë¡œì§
if os.path.exists(CHROMA_PATH):
    vectorstore = Chroma(persist_directory=CHROMA_PATH, embedding_function=OpenAIEmbeddings())
    print("âœ… ê¸°ì¡´ DB ë¡œë“œë¨")
else:
    vectorstore = load_and_process_data()

retriever = vectorstore.as_retriever() if vectorstore else None
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

template = """
ë‹¹ì‹ ì€ ë¶€ì‚°ëŒ€í•™êµ ê³µê°œ ì •ë³´ ë´‡ì…ë‹ˆë‹¤. 
[ë¬¸ë§¥]ì„ ë³´ê³  ë‹µë³€í•˜ì„¸ìš”. ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  í•˜ì„¸ìš”.

[ë¬¸ë§¥]:
{context}

[ì§ˆë¬¸]:
{question}

[ë‹µë³€]:
"""
prompt = ChatPromptTemplate.from_template(template)


def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)


rag_chain = None
if retriever:
    rag_chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
    )


class QueryRequest(BaseModel):
    query: str


@app.post("/chat")
async def chat(request: QueryRequest):
    if not rag_chain:
        return {"answer": "í•™ìŠµëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ./data í´ë”ì— íŒŒì¼ì„ ë„£ê³  ì¬ì‹œì‘í•´ë³´ì„¸ìš”."}
    response = rag_chain.invoke(request.query)
    return {"answer": response}


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)